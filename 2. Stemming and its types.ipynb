{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "- Stemming in Natural Language Processing (NLP) is the process of reducing a word to its root form or base form (known as the stem). The goal of stemming is to remove suffixes (and sometimes prefixes) from a word to simplify its representation, helping to treat related words as the same during text processing.\n",
    "\n",
    "#### For example:\n",
    "\"running\", \"runner\", and \"ran\" → run\n",
    "\"studies\", \"studying\", and \"studied\" → studi\n",
    "\n",
    "### Why Stemming is Important\n",
    "- Normalization: Reduces words to a common form so that variations of the same word are treated identically.\n",
    "- Efficiency: Reduces vocabulary size, making text processing faster and resource-efficient.\n",
    "- Search & Retrieval: Improves accuracy in search engines by grouping word variations (e.g., \"run\" and \"running\").\n",
    "\n",
    "### Algorithms for Stemming\n",
    "- Porter Stemmer:\n",
    "The most common stemming algorithm.\n",
    "Applies a series of rules to remove common suffixes like -ing, -ed, -s.\n",
    "Example: \"running\" → \"run\".\n",
    "\n",
    "- Lancaster Stemmer:\n",
    "A more aggressive stemmer than Porter Stemmer.\n",
    "Often results in very short stems.\n",
    "Example: \"running\" → \"run\", \"playing\" → \"play\".\n",
    "\n",
    "- Snowball Stemmer:\n",
    "An improved version of the Porter Stemmer with better efficiency and flexibility for multiple languages.\n",
    "\n",
    "### Stemming vs Lemmatization\n",
    "- Stemming:\n",
    "Cuts off prefixes or suffixes using heuristic rules.\n",
    "May produce non-dictionary words (e.g., \"studies\" → \"studi\").\n",
    "\n",
    "- Lemmatization:\n",
    "Maps words to their dictionary form (lemma) using vocabulary and grammar.\n",
    "Produces valid words (e.g., \"studies\" → \"study\").\n",
    "In summary: Stemming simplifies words to their root form by truncating suffixes. While it is fast and computationally inexpensive, it can sometimes result in inaccurate or \"chopped\" stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "  \"run\", \"running\", \"runs\", \"runner\",\n",
    "  \"write\", \"writing\", \"writes\", \"wrote\", \"written\",\n",
    "  \"jump\", \"jumping\", \"jumps\", \"jumped\",\n",
    "  \"swim\", \"swimming\", \"swims\", \"swam\", \"swum\",\n",
    "  \"go\", \"going\", \"goes\", \"went\", \"gone\",\n",
    "  \"read\", \"reading\", \"reads\",\n",
    "  \"love\", \"loving\", \"loves\", \"loved\",\n",
    "  \"walk\", \"walking\", \"walks\", \"walked\",\n",
    "  \"try\", \"trying\", \"tries\", \"tried\",\n",
    "  \"study\", \"studying\", \"studies\", \"studied\",\n",
    "  \"fly\", \"flying\", \"flies\", \"flew\", \"flown\",\n",
    "  \"buy\", \"buying\", \"buys\", \"bought\",\n",
    "  \"speak\", \"speaking\", \"speaks\", \"spoke\", \"spoken\",\n",
    "  \"see\", \"seeing\", \"sees\", \"saw\", \"seen\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of changed words:\n",
      "running -> run\n",
      "runs -> run\n",
      "writing -> write\n",
      "writes -> write\n",
      "jumping -> jump\n",
      "jumps -> jump\n",
      "jumped -> jump\n",
      "swimming -> swim\n",
      "swims -> swim\n",
      "going -> go\n",
      "goes -> goe\n",
      "reading -> read\n",
      "reads -> read\n",
      "loving -> love\n",
      "loves -> love\n",
      "loved -> love\n",
      "walking -> walk\n",
      "walks -> walk\n",
      "walked -> walk\n",
      "try -> tri\n",
      "trying -> tri\n",
      "tries -> tri\n",
      "tried -> tri\n",
      "study -> studi\n",
      "studying -> studi\n",
      "studies -> studi\n",
      "studied -> studi\n",
      "fly -> fli\n",
      "flying -> fli\n",
      "flies -> fli\n",
      "buying -> buy\n",
      "buys -> buy\n",
      "speaking -> speak\n",
      "speaks -> speak\n",
      "seeing -> see\n",
      "sees -> see\n",
      "\n",
      "List of unchanged words:\n",
      "run -> run\n",
      "runner -> runner\n",
      "write -> write\n",
      "wrote -> wrote\n",
      "written -> written\n",
      "jump -> jump\n",
      "swim -> swim\n",
      "swam -> swam\n",
      "swum -> swum\n",
      "go -> go\n",
      "went -> went\n",
      "gone -> gone\n",
      "read -> read\n",
      "love -> love\n",
      "walk -> walk\n",
      "flew -> flew\n",
      "flown -> flown\n",
      "buy -> buy\n",
      "bought -> bought\n",
      "speak -> speak\n",
      "spoke -> spoke\n",
      "spoken -> spoken\n",
      "see -> see\n",
      "saw -> saw\n",
      "seen -> seen\n"
     ]
    }
   ],
   "source": [
    "changed = {word: stemming.stem(word) for word in words if word != stemming.stem(word)}\n",
    "unchanged = {word: stemming.stem(word) for word in words if word == stemming.stem(word)}\n",
    "\n",
    "# Display the results\n",
    "print(\"List of changed words:\")\n",
    "for word, stem in changed.items():\n",
    "    print(f\"{word} -> {stem}\")\n",
    "\n",
    "print(\"\\nList of unchanged words:\")\n",
    "for word, stem in unchanged.items():\n",
    "    print(f\"{word} -> {stem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of changed words:\n",
      "running -> run\n",
      "runs -> run\n",
      "writing -> write\n",
      "writes -> write\n",
      "jumping -> jump\n",
      "jumps -> jump\n",
      "jumped -> jump\n",
      "swimming -> swim\n",
      "swims -> swim\n",
      "going -> go\n",
      "goes -> goe\n",
      "reading -> read\n",
      "reads -> read\n",
      "loving -> love\n",
      "loves -> love\n",
      "loved -> love\n",
      "walking -> walk\n",
      "walks -> walk\n",
      "walked -> walk\n",
      "try -> tri\n",
      "trying -> tri\n",
      "tries -> tri\n",
      "tried -> tri\n",
      "study -> studi\n",
      "studying -> studi\n",
      "studies -> studi\n",
      "studied -> studi\n",
      "fly -> fli\n",
      "flying -> fli\n",
      "flies -> fli\n",
      "buying -> buy\n",
      "buys -> buy\n",
      "speaking -> speak\n",
      "speaks -> speak\n",
      "seeing -> see\n",
      "sees -> see\n",
      "\n",
      "List of unchanged words:\n",
      "run -> run\n",
      "runner -> runner\n",
      "write -> write\n",
      "wrote -> wrote\n",
      "written -> written\n",
      "jump -> jump\n",
      "swim -> swim\n",
      "swam -> swam\n",
      "swum -> swum\n",
      "go -> go\n",
      "went -> went\n",
      "gone -> gone\n",
      "read -> read\n",
      "love -> love\n",
      "walk -> walk\n",
      "flew -> flew\n",
      "flown -> flown\n",
      "buy -> buy\n",
      "bought -> bought\n",
      "speak -> speak\n",
      "spoke -> spoke\n",
      "spoken -> spoken\n",
      "see -> see\n",
      "saw -> saw\n",
      "seen -> seen\n"
     ]
    }
   ],
   "source": [
    "changed = {word: snow_stemmer.stem(word) for word in words if word != snow_stemmer.stem(word)}\n",
    "unchanged = {word: snow_stemmer.stem(word) for word in words if word == snow_stemmer.stem(word)}\n",
    "\n",
    "# Display the results\n",
    "print(\"List of changed words:\")\n",
    "for word, stem in changed.items():\n",
    "    print(f\"{word} -> {stem}\")\n",
    "\n",
    "print(\"\\nList of unchanged words:\")\n",
    "for word, stem in unchanged.items():\n",
    "    print(f\"{word} -> {stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('fairly'), stemming.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_stemmer.stem('fairly'), snow_stemmer.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
